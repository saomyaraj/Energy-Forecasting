{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Attention, Dense, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "# Load and preprocess the new dataset\n",
        "path = \"/content/AEP_hourly.csv\"  # Update the path to the new dataset\n",
        "data = pd.read_csv(path, parse_dates=['Datetime'])\n",
        "\n",
        "# Set Datetime as index\n",
        "data.set_index('Datetime', inplace=True)\n",
        "\n",
        "# Handle missing values\n",
        "data.fillna(method='ffill', inplace=True)  # Forward fill for simplicity; adjust as needed\n",
        "\n",
        "# Normalize features\n",
        "scalers = {}\n",
        "features = ['Temperature', 'Relative Humidity', 'Wind Speed', 'Precipitation', 'Is_Weekend_Holiday']\n",
        "for feature in features:\n",
        "    scalers[feature] = MinMaxScaler()\n",
        "    data[feature] = scalers[feature].fit_transform(data[[feature]])\n",
        "\n",
        "# Normalize AEP_MW separately\n",
        "scaler_aep = MinMaxScaler()\n",
        "data['AEP_MW'] = scaler_aep.fit_transform(data[['AEP_MW']])\n",
        "\n",
        "# Define time window and reshape data\n",
        "n_timesteps = 24  # Using 24 hours as the time window\n",
        "features_list = features + ['AEP_MW']\n",
        "data_reshaped = data[features_list]\n",
        "\n",
        "# Reshape the data for LSTM\n",
        "n_samples = data_reshaped.shape[0] // n_timesteps\n",
        "reshaped_data = data_reshaped.values[:n_samples * n_timesteps].reshape(n_samples, n_timesteps, len(features_list))\n",
        "\n",
        "# Split data into features and target\n",
        "X = reshaped_data[:, :-1, :]\n",
        "Y = reshaped_data[:, -1, -1]  # Only target is the last feature ('AEP_MW')\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"The training set has {X_train.shape}\")\n",
        "print(f\"The test set has {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-UDGxdW2jSO",
        "outputId": "1d190599-2952-4120-eccd-2bec5dc76ee7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training set has (4042, 23, 6)\n",
            "The test set has (1011, 23, 6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-fa45a4ea249d>:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  data.fillna(method='ffill', inplace=True)  # Forward fill for simplicity; adjust as needed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_with_attention(units=50, dropout_rate=0.2, learning_rate=0.001):\n",
        "    inputs = tf.keras.Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
        "\n",
        "    # LSTM layer with attention\n",
        "    lstm_out = Bidirectional(LSTM(units, return_sequences=True))(inputs)\n",
        "    attention_out = Attention()([lstm_out, lstm_out])\n",
        "    dropout_out = Dropout(dropout_rate)(attention_out)\n",
        "\n",
        "    # Additional LSTM layers\n",
        "    lstm_out = Bidirectional(LSTM(units, return_sequences=True))(dropout_out)\n",
        "    dropout_out = Dropout(dropout_rate)(lstm_out)\n",
        "    lstm_out = Bidirectional(LSTM(units))(dropout_out)\n",
        "\n",
        "    # Dense layers\n",
        "    dense_out = Dense(units, activation='leaky_relu')(lstm_out)\n",
        "    outputs = Dense(1)(dense_out)  # Predicting AEP_MW\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "xVUIOBuE2l6K"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train and evaluate the attention model\n",
        "def train_and_evaluate_attention_model(units, dropout_rate, learning_rate):\n",
        "    model = build_model_with_attention(units, dropout_rate, learning_rate)\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, Y_train,\n",
        "        validation_data=(X_test, Y_test),\n",
        "        epochs=100,\n",
        "        batch_size=64,\n",
        "        callbacks=[early_stopping, reduce_lr],\n",
        "        verbose=1\n",
        "    )\n",
        "    return model, history\n",
        "\n",
        "# Train and evaluate the model with attention\n",
        "print(\"Training model with attention mechanism\")\n",
        "model, history = train_and_evaluate_attention_model(\n",
        "    best_params['units'],\n",
        "    best_params['dropout_rate'],\n",
        "    best_params['learning_rate']\n",
        ")\n",
        "\n",
        "val_rmse = min(history.history['val_loss'])\n",
        "if val_rmse < best_rmse:\n",
        "    best_rmse = val_rmse\n",
        "    best_params['attention'] = True\n",
        "\n",
        "print(f\"Best RMSE: {best_rmse} with params: {best_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP_fz-hc2p7R",
        "outputId": "d52c63e4-acba-425b-ffba-655e8c9307d2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with attention mechanism\n",
            "Epoch 1/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 0.0377 - mae: 0.1447 - val_loss: 0.0148 - val_mae: 0.0942 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0146 - mae: 0.0927 - val_loss: 0.0141 - val_mae: 0.0876 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0127 - mae: 0.0852 - val_loss: 0.0099 - val_mae: 0.0749 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0092 - mae: 0.0722 - val_loss: 0.0071 - val_mae: 0.0648 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0072 - mae: 0.0653 - val_loss: 0.0073 - val_mae: 0.0660 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0058 - mae: 0.0587 - val_loss: 0.0037 - val_mae: 0.0477 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0040 - mae: 0.0492 - val_loss: 0.0038 - val_mae: 0.0499 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0036 - mae: 0.0467 - val_loss: 0.0032 - val_mae: 0.0444 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0028 - mae: 0.0411 - val_loss: 0.0028 - val_mae: 0.0418 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0027 - mae: 0.0402 - val_loss: 0.0022 - val_mae: 0.0373 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0027 - mae: 0.0405 - val_loss: 0.0020 - val_mae: 0.0346 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0021 - mae: 0.0357 - val_loss: 0.0018 - val_mae: 0.0324 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0023 - mae: 0.0367 - val_loss: 0.0022 - val_mae: 0.0376 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0345 - val_loss: 0.0027 - val_mae: 0.0405 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0026 - mae: 0.0400 - val_loss: 0.0018 - val_mae: 0.0325 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0341 - val_loss: 0.0020 - val_mae: 0.0346 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0371 - val_loss: 0.0017 - val_mae: 0.0322 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0322 - val_loss: 0.0014 - val_mae: 0.0288 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0301 - val_loss: 0.0015 - val_mae: 0.0296 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0310 - val_loss: 0.0014 - val_mae: 0.0289 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0300 - val_loss: 0.0014 - val_mae: 0.0286 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0017 - mae: 0.0309 - val_loss: 0.0014 - val_mae: 0.0286 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0015 - mae: 0.0296 - val_loss: 0.0016 - val_mae: 0.0307 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0013 - val_mae: 0.0272 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0013 - val_mae: 0.0274 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0014 - mae: 0.0285 - val_loss: 0.0013 - val_mae: 0.0277 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0273 - val_loss: 0.0015 - val_mae: 0.0296 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0276 - val_loss: 0.0012 - val_mae: 0.0264 - learning_rate: 2.5000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0282 - val_loss: 0.0012 - val_mae: 0.0264 - learning_rate: 2.5000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0274 - val_loss: 0.0012 - val_mae: 0.0259 - learning_rate: 1.2500e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0273 - val_loss: 0.0012 - val_mae: 0.0255 - learning_rate: 1.2500e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0013 - mae: 0.0274 - val_loss: 0.0012 - val_mae: 0.0259 - learning_rate: 1.2500e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0013 - mae: 0.0279 - val_loss: 0.0012 - val_mae: 0.0263 - learning_rate: 1.2500e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - mae: 0.0267 - val_loss: 0.0012 - val_mae: 0.0256 - learning_rate: 1.2500e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0273 - val_loss: 0.0011 - val_mae: 0.0252 - learning_rate: 1.2500e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0263 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 6.2500e-05\n",
            "Epoch 37/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0264 - val_loss: 0.0011 - val_mae: 0.0254 - learning_rate: 6.2500e-05\n",
            "Epoch 38/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0259 - val_loss: 0.0011 - val_mae: 0.0250 - learning_rate: 6.2500e-05\n",
            "Epoch 39/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0265 - val_loss: 0.0011 - val_mae: 0.0253 - learning_rate: 6.2500e-05\n",
            "Epoch 40/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0261 - val_loss: 0.0012 - val_mae: 0.0257 - learning_rate: 6.2500e-05\n",
            "Epoch 41/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0258 - val_loss: 0.0011 - val_mae: 0.0251 - learning_rate: 3.1250e-05\n",
            "Epoch 42/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0259 - val_loss: 0.0011 - val_mae: 0.0249 - learning_rate: 3.1250e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0012 - mae: 0.0266 - val_loss: 0.0011 - val_mae: 0.0247 - learning_rate: 3.1250e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0258 - val_loss: 0.0011 - val_mae: 0.0247 - learning_rate: 3.1250e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0262 - val_loss: 0.0011 - val_mae: 0.0248 - learning_rate: 3.1250e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0250 - learning_rate: 1.5625e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0250 - val_loss: 0.0011 - val_mae: 0.0247 - learning_rate: 1.5625e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0257 - val_loss: 0.0011 - val_mae: 0.0252 - learning_rate: 1.5625e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0261 - val_loss: 0.0011 - val_mae: 0.0247 - learning_rate: 1.5625e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0261 - val_loss: 0.0011 - val_mae: 0.0245 - learning_rate: 1.5625e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0257 - val_loss: 0.0011 - val_mae: 0.0248 - learning_rate: 1.5625e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 0.0011 - val_mae: 0.0247 - learning_rate: 1.5625e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0012 - mae: 0.0259 - val_loss: 0.0011 - val_mae: 0.0247 - learning_rate: 1.5625e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 0.0011 - val_mae: 0.0246 - learning_rate: 1.5625e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0265 - val_loss: 0.0011 - val_mae: 0.0245 - learning_rate: 1.5625e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0250 - val_loss: 0.0011 - val_mae: 0.0245 - learning_rate: 7.8125e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0262 - val_loss: 0.0011 - val_mae: 0.0245 - learning_rate: 7.8125e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 0.0011 - val_mae: 0.0247 - learning_rate: 7.8125e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0262 - val_loss: 0.0011 - val_mae: 0.0245 - learning_rate: 7.8125e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0250 - val_loss: 0.0011 - val_mae: 0.0245 - learning_rate: 7.8125e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 0.0011 - val_mae: 0.0245 - learning_rate: 3.9063e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0255 - val_loss: 0.0011 - val_mae: 0.0245 - learning_rate: 3.9063e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0011 - mae: 0.0249 - val_loss: 0.0011 - val_mae: 0.0245 - learning_rate: 3.9063e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0257 - val_loss: 0.0011 - val_mae: 0.0245 - learning_rate: 3.9063e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0258 - val_loss: 0.0011 - val_mae: 0.0245 - learning_rate: 3.9063e-06\n",
            "Best RMSE: 0.0010768871288746595 with params: {'units': 50, 'dropout_rate': 0.2, 'learning_rate': 0.001, 'l2_lambda': 0.001, 'attention': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, data):\n",
        "    # Ensure data is in the same shape as training data\n",
        "    # The input data should have the shape (1, n_timesteps - 1, number of features)\n",
        "    prediction = model.predict(data)\n",
        "    return scaler_aep.inverse_transform(prediction.reshape(-1, 1))\n",
        "\n",
        "# Define a function to prepare the input data\n",
        "def prepare_input_data(datetime, temperature, humidity, wind_speed, precipitation, is_weekend_holiday):\n",
        "    # Create a DataFrame with the new input values\n",
        "    input_data = pd.DataFrame({\n",
        "        'Datetime': [datetime],\n",
        "        'Temperature': [temperature],\n",
        "        'Relative Humidity': [humidity],\n",
        "        'Wind Speed': [wind_speed],\n",
        "        'Precipitation': [precipitation],\n",
        "        'Is_Weekend_Holiday': [is_weekend_holiday],\n",
        "        'AEP_MW': [0]\n",
        "    })\n",
        "\n",
        "    # Set Datetime as index\n",
        "    input_data.set_index('Datetime', inplace=True)\n",
        "\n",
        "    # Normalize the features\n",
        "    for feature in ['Temperature', 'Relative Humidity', 'Wind Speed', 'Precipitation', 'Is_Weekend_Holiday']:\n",
        "        input_data[feature] = scalers[feature].transform(input_data[[feature]])\n",
        "\n",
        "    # Create a time window (e.g., last 24 hours)\n",
        "    # Note: You need historical data for a valid time window, here we just repeat the values for demonstration\n",
        "    input_data = pd.concat([input_data] * (n_timesteps - 1), ignore_index=True)\n",
        "\n",
        "    # Normalize the target feature\n",
        "    input_data['AEP_MW'] = scaler_aep.transform(input_data[['AEP_MW']])\n",
        "\n",
        "    # Prepare data for prediction\n",
        "    input_array = input_data[features_list].values.reshape(1, n_timesteps - 1, len(features_list))\n",
        "    return input_array\n",
        "\n",
        "# Example usage\n",
        "datetime = pd.to_datetime('2009-09-13 18:00:00')  # Replace with actual datetime\n",
        "temperature = 2.78  # Example temperature\n",
        "humidity = 72.24  # Example relative humidity\n",
        "wind_speed = 16.1  # Example wind speed\n",
        "precipitation = 0  # Example precipitation\n",
        "is_weekend_holiday = True  # Example: 0 for False, 1 for True\n",
        "\n",
        "# Prepare input data\n",
        "input_data = prepare_input_data(datetime, temperature, humidity, wind_speed, precipitation, is_weekend_holiday)\n",
        "\n",
        "# Ensure the model is trained before prediction\n",
        "model = build_model_with_attention(best_params['units'], best_params['dropout_rate'], best_params['learning_rate'])\n",
        "\n",
        "# Predict the value\n",
        "predicted_value = predict(model, input_data)\n",
        "print(f\"Predicted AEP_MW: {predicted_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyREyc9G2vP_",
        "outputId": "2607c622-f8cc-4318-e5e9-a527547fd481"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step\n",
            "Predicted AEP_MW: [[10702.376]]\n"
          ]
        }
      ]
    }
  ]
}